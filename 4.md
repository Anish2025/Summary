# React: Synergizing Reasoning and Acting in Language Models

- This paper, published in early 2023, explores how to induce reasoning into Large Language Models (LLMs).
- At the time, LLMs were primarily seen as conversational tools, and the goal was to make them more like autonomous reasoning entities.
- The paper's approach is reflected in current AI practices, such as the use of first-person anthropomorphized reasoning in coding assistants.
- The core idea is to have LLMs generate both reasoning traces and task-specific actions in an interleaved manner, creating synergy between the two.
- This approach aims to improve the model's ability to:
  - Track and update action plans
  - Handle exceptions
  - Gather information from external sources
- The method, named **React**, is applied to language and decision-making tasks, demonstrating its effectiveness compared to state-of-the-art baselines.
- React addresses issues like hallucination and error propagation in chain-of-thought reasoning by interacting with external APIs like Wikipedia.
- The key is a continuous loop of **observe → reason → act**, known as the **agentic loop**.
- React outperforms imitation and reinforcement learning methods on interactive decision-making benchmarks, even with limited in-context examples.
- The paper emphasizes the importance of combining task-oriented actions with verbal reasoning, mirroring human intelligence.
- In the context of the paper, observation is implicit, focusing on reasoning and acting.
- The action space is augmented with reasoning actions (reasoning traces) that don't directly affect the environment but help the model think about the goal.
- Reasoning becomes an action itself—a "tool-less action" within the textual space.
- Example used: **Hotspot QA**, illustrating the benefits of React.
- Standard LLMs (like GPT-3.5) often hallucinate.
- Chain-of-thought prompting can still lead to incorrect answers based on wrong assumptions.
- Simply giving the LLM actions to perform (like searching) doesn't always help.
- React combines reasoning and acting, allowing the model to:
  - Think through the problem
  - Search for relevant information
  - Act based on that information
- The **"thought" action** is a key innovation, representing an action of thinking that doesn’t directly affect the external world.
- The paper formalizes the **observe → reason → act** loop, highlighting the importance of the reasoning step for agentic behavior.
- Example: an agent trying to find a pepper shaker in a room—illustrating the importance of the cycle.
- The agent setup involves interacting with an environment, receiving observations, and taking actions.
- The action space is augmented with a **"thought action"**, enabling internal reasoning.
- A **thought** is defined as a reasoning trace that doesn’t affect the external environment but helps compose useful information and update the context.
- Conclusion: React improves results compared to standard or chain-of-thought prompting.

# MemGPT: Towards LLMs with Long-Term Memory

- This paper addresses the challenge of **finite context windows in LLMs** and how to maintain continuous conversations with knowledge exceeding that limit.
- It draws an analogy to **virtual memory management** in operating systems, where programs larger than physical memory can run by swapping data between RAM and disk.
- The paper proposes a system similar to a **Retrieval-Augmented Generation (RAG)** setup, with:
  - Backend storage for facts
  - Mechanism to move information in and out of the context window
- It creates a RAG system where:
  - Conversational context is continuously added
  - The data in RAG comes from past conversational history
- Examples show how the system remembers facts about the user to provide more relevant and personalized responses.
- The system creates **"memory pressure"** to identify valuable information to retain, such as birthdays and relationships.
- It searches its memory to retrieve relevant context and appends it to current conversation inputs for better responses.
- The system performs **memory management**, such as updating relationship statuses when a user reports a breakup.
- Architecture components include:
  - System prompt
  - User messages
  - Relevant context retrieved from storage
- Main takeaway: **memory management is critical** for building effective agentic systems and improving interaction quality.
- Can be implemented with internal memory for **privacy and confidentiality**, especially in enterprise applications.
- Memory management involves not just logging, but also **abstractive summarization** to distill key info.
- Highlights the importance of preserving proprietary information within in-house agentic systems.
- The paper contrasts simple LLM calls with **agentic systems** like ChatGPT that include their own memory management.
- Conclusion: Memory management is essential to avoid "gross dementia" in agentic systems.
