# AI Agent Week 4.1: Tools, Prompting, and Text to SQL

##  Introduction

- Building effective AI agents that can accurately extract data from documents and generate outputs, such as SQL queries, requires a combination of powerful tools, high-quality data preparation, and expertise in prompting and engineering.



##  Data Extraction: Challenges and Observations
- Three extraction methods were tried:
    - **Docling**: Incomplete extraction (columns missed).    
    - **PDF Plumber**: Numerical errors (e.g., 243.97 became 439.70), and missing rows.
    - **OpenAI Prompting**: Multiple columns missed.



##  Prompting vs. Context Engineering

- Prompting is not trivial; it's being rebranded as **"context engineering"**.
- **PDF Plumber** is not AI; lacks vision-language capabilities.
- **Docling** is the best in open source but limited due to universal design goals.
- **OCR tools (e.g., Tesseract)** are outdated and ineffective in 2025.
    

### Solution Pathways:

- Use **layout transformer** and **table former** models for structured, high-fidelity extraction.
- **Frontier models (e.g., Gemini, OpenAI)** provide perfect extractions but were intentionally withheld to encourage learning.




## The Craft of Prompting

- Prompting is iterative, akin to **writing poetry**.
- Prompting = scripting = new programming.
    
- Mastery requires:
    - Meta prompting.
    - Iteration.
    - Intentional structure.
        
- Only two paths:
    - Discover effective prompts through iteration.   
    - Don’t get it right, thus don’t deserve the correct prompt.
    


## Prompt Templates and Tools

- Templates:
    - **Co-Star Prompt**: Valid and government-backed.
    - **DSPY**: Still relevant but situational.
        
- Local vs. Frontier Model Results:
    - **OpenAI Frontier** model outperformed local ones.
    - Local trials included **LLaMA 3.2B**, which proved too small.
        


## SQL Generation and Data Preparation

- Training via LLM and local models gave vastly different outputs due to:
    - Quality of the SQL-question pairs.
    - Lack of schema-aware generation.
    - Insufficient attention to query variety (e.g., range queries, subqueries).
    
### Best Practices:
- Avoid **OCR**, use **Vision-Language** models.
- Use **RAG (Retrieval Augmented Generation)**: retrieve relevant neighbors for SQL generation.
- Treat it as **K-Nearest Neighbor** problem.

### Steps to Improve:

1. Hand-comment DDL and schema.
2. Hand-generate ~24 SQL queries.
3. Use LLM to **generate permutations** around these examples.
4. Avoid subqueries; use **from-object patterns**.
5. Train on **well-structured, well-documented SQL**.




## Model Size and Privacy Considerations

- Recommended model sizes for SQL generation:
    - **Minimum**: 7B.
    - **Optimal**: ~30B.    
    - **Excellent**: 70B.
- Avoid frontier models in production due to **schema leakage**.
    


## Effort, Practice, and Skill Development

- Effort correlates with output quality.
- Reference to **10,000-hour rule** and musicians practicing 14+ hours/day.    
- Excellence in prompting requires:
    - Repeated practice.
    - Deep familiarity with context engineering.
        



## Data Augmentation with LLMs
- Start with **user-intent (how-might-we)** perspective.
- Manually write 24 “how maybe” use cases.
- Generate query variants via LLM.
- Demand justification for each generated variant to ensure diversity.
    


## RAG Collections and Implementation Details

- VA/Wana’s “training” = **RAG**, not actual training.
- Structure includes:
    - **FedEx Pricing Banner DDL**.
    - **Documentation descriptions**.
    - **Q&A pairs**.
        
- Two collections used; correlation is implementation-specific, not conceptual.



## Future Directions and Training Own Models
- Fine-tuning your own **text-to-SQL model** using domain-specific queries is the true next step.
- Not covered in this course, but hinted as part of advanced future sessions.


## Key Takeaways
- **Prompting is hard** — it's now called _context engineering_ and must be iteratively refined.
- **Old tools fail** — use **LayoutLM + TableFormer** or **frontier models** for clean data extraction.
- **SQL generation needs quality examples** — handwrite ~24 clear queries, then expand using LLMs.
- Use **RAG** as a _nearest-neighbor_ method, not real training.
- **Minimum model size:** 7B; **ideal:** 30B. Avoid frontier APIs for private data.
- **Mastery = effort** — treat prompting like coding; 10,000 hours builds expertise.
- **Next step:** fine-tune your own models (beyond RAG).
